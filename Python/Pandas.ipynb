{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas - Python Data Analysis Library\n",
    "`pandas` is a software library written for data manipulation and analysis. It contains the `DataFrame` object for manipulating numerical tables and time series data. The dataframe in pandas combines aspects of `MATLAB` indexing with functionality similar to the statistical programming language `R`.\n",
    "First, since `pandas` is an auxiliary library, you must allows load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` provides an easy to use function `read_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table\n",
    "dftemps = pd.read_table('data//GlobalTempbyMonth.txt', header=None, index_col=0, sep=r'\\s+')\n",
    "print(type(dftemps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data\n",
    "dftemps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataframe has row and column headers that can be either strings or numbers. The index for the rows in the dataframe `dftemps` appears as the first column of this file - the dates. The index of a dataframe is also bolded when printed. Dataframes must have a column containing unique values for every row; the index of a dataframe is this unique column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show index\n",
    "dftemps.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` has a function for reading excel files, `read_excel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcarbon = pd.read_excel('data/GlobalCarbonBudget2022.xlsx','Global Carbon Budget', skiprows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfcarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfcarbon.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {}\n",
    "for name in dfcarbon.columns:\n",
    "    namelist = name.split(' ')\n",
    "    name_dict[name] = ' '.join(namelist[0:2])\n",
    "print(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdfcarbon = dfcarbon.rename(columns = name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfcarbon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing into a dataframe (aka slicing a dataframe)\n",
    "The two methods that are essential to accessing information in a dataframe are `loc` and `iloc`. `loc` takes the row and column names as strings. `iloc` takes only integers that label the rows and columns. Using `iloc` allows you to index a dataframe using only numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dftemps.iloc[3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemps.loc['1903/10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcarbon['ocean sink'][0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcarbon.loc[0:6,'ocean sink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcarbon.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfcarbon['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'ocean sink'\n",
    "dfcarbon.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding to Dataframes\n",
    "You can add columns to a dataframe with the following syntax. Notice that `pandas` has a number of methods associated with dataframes, such as `mean`, `min`, `max`. These methods are meant to act directly on the dataframe. Other statistical tools are available directly from pandas, you can visit [Dataframe statistical methods](https://studyopedia.com/pandas/statistical-functions/). The basic statistical tools you have are\n",
    "| Method      | Description                                      |\n",
    "|-------------|--------------------------------------------------|\n",
    "| sum()       | Return the sum of the values.                    |\n",
    "| count()     | Return the count of non-empty values.            |\n",
    "| max()       | Return the maximum of the values.                |\n",
    "| min()       | Return the minimum of the values.                |\n",
    "| mean()      | Return the mean of the values.                   |\n",
    "| median()    | Return the median of the values.                 |\n",
    "| std()       | Return the standard deviation of the values.     |\n",
    "| describe()  | Return the summary statistics for each column.   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new columns\n",
    "dftemps['average'] = dftemps.mean(axis=1)\n",
    "dftemps['min'] = dftemps.min(axis=1)\n",
    "dftemps['max'] = dftemps.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemps.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by average\n",
    "dftemps2 = dftemps.sort_values(by='average', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemps2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get a certain column\n",
    "dftemps2.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfcarbon['total carbon'] = newdfcarbon['fossil emissions'] + newdfcarbon['land-use change'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfcarbon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reforming a Dataframe\n",
    "Part of data wrangling is manipulating data into the most useful form. Suppose we didn't want the average temperature for every month, but every year. You can use `groupby` to group data in a different way. *Can you describe what happens in each of the following lines?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by year and calculate the average temperature\n",
    "dftemps['year'] = list(map(lambda x:x[:4], dftemps.index))\n",
    "year_average = dftemps.groupby(dftemps.year).average.mean()\n",
    "dftemps.set_index(dftemps.year)\n",
    "year_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemps['year'] = list(map(lambda x:x[:4], dftemps.index))\n",
    "type(year_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can look into using `pivot_table`, which by also groups rows by common entries (specified by the `index` parameter) and calculates the `mean` (you can also specify other operations) across them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivottemps = pd.pivot_table(dftemps, values= ['average','min','max'], index='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivottemps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering a Dataframe\n",
    "You can reorder the columns by using the `iloc` method and listing the column indices in the new order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = newdfcarbon.iloc[:,[0,1,2,8,3,4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to a File\n",
    "After manipulating any data using a dataframe, you can write your modified table to a `csv`, `excel`, or `json` file easily. With any dataframe, you can use the methods: `to_csv`, `to_excel`, or `to_json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfcarbon.to_csv('pandas_carbon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfcarbon.to_excel('pandas_carbon.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfcarbon.to_json('pandas_carbon.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One more thing....\n",
    "`matplotlib` can take dataframe columns as arguments. This allows you to plot information from dataframes without too much effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot(newdfcarbon.Year, newdfcarbon['total carbon'],newdfcarbon.Year,newdfcarbon['atmospheric growth'])\n",
    "mp.xlabel('Year')\n",
    "mp.ylabel('Carbon emitted (Gt)')\n",
    "mp.legend(['total carbon','atmospheric growth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oops...One more thing\n",
    "This gives me an idea. We have carbon emission data. Is there a correlation between those emissions and the temperature anomaly in `globaltemps.txt`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtemps = pd.read_table('data/globaltemps.txt', header=None)\n",
    "pgtemps = gtemps[(gtemps[0]>1958) & (gtemps[0]<2022)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgtemps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Explorin'\n",
    "After reading about *Exercise 3: Explorin'*, use this space to explore the file `Exoplanet_Archive10.2025.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create exoplanet dataframe\n",
    "dfplanets = pd.read_csv('data/Exoplanet_Archive10.2025.csv')\n",
    "dfplanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
