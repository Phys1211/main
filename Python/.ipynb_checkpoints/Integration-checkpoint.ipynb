{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Integration\n",
    "\n",
    "In calculus, you learned that integration finds the area under a curve. You computed integrals using **Riemann sums** - dividing the region into rectangles and adding up their areas. As you made the rectangles narrower, the approximation improved.\n",
    "\n",
    "**Numerical integration** uses the same core idea, but with more sophisticated shapes than rectangles. Instead of taking the limit as the width goes to zero (which requires knowing the function analytically), we use a finite number of carefully chosen sample points to get accurate approximations.\n",
    "\n",
    "## Why Numerical Integration Matters\n",
    "\n",
    "Numerical integration is essential in physics and engineering because:\n",
    "- **Many integrals have no closed-form solution** - You can't write down an answer using elementary functions\n",
    "- **Experimental data is discrete** - Real measurements give you points, not continuous functions  \n",
    "- **Complex realistic problems** - Numerical methods handle messy real-world situations that symbolic math cannot\n",
    "\n",
    "**Connection to Differentiation**: In the previous notebook, we approximated derivatives using finite differences. Integration is the inverse operation - instead of finding slopes, we're finding areas. However, unlike differentiation (which amplifies noise), integration tends to **smooth out** errors. This makes numerical integration generally more accurate and stable than numerical differentiation!\n",
    "\n",
    "## Quadrature\n",
    "\n",
    "**Quadrature** is the mathematical term for numerical integration. The name comes from the ancient Greek problem of finding a square with the same area as a given curved region (\"squaring the circle\").\n",
    "\n",
    "We will focus on three fundamental methods:\n",
    "\n",
    "* **Trapezoid Rule** – Approximates the area using trapezoids  \n",
    "* **Simpson's Rule** – Uses parabolic segments for improved accuracy  \n",
    "* **Romberg Integration** – Refines estimates iteratively through extrapolation to maximum accuracy\n",
    "\n",
    "Each method approximates an integral as a weighted sum of function values:\n",
    "\n",
    "$$\n",
    "\\int_a^b f(x)\\,dx \\approx \\sum_{k=1}^N w_k f(x_k)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x_k$ are the sample points where we evaluate the function  \n",
    "- $w_k$ are weights that depend on the chosen method\n",
    "- $N$ is the number of sample points\n",
    "- $h = (b-a)/N$ is typically the spacing between points (the \"step size\")\n",
    "\n",
    "The choice of method directly impacts accuracy. The Trapezoid Rule is simple and works well for smooth functions. Simpson's Rule achieves better accuracy by fitting curves instead of straight lines. Romberg Integration takes this further by systematically refining estimates - each iteration roughly doubles the number of accurate digits!\n",
    "\n",
    "In the following sections, we'll explore each method, understand how they work, and learn when to use them.ccuracy with fewer steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trapezoid Rule\n",
    "\n",
    "One of the simplest numerical integration methods is the **Trapezoid Rule**, which approximates the area under a curve by dividing it into a series of trapezoids. Instead of approximating the function with rectangles (as in Riemann sums), we use trapezoids to achieve a more accurate estimate of the integral.\n",
    "\n",
    "Think of it this way: if you connect consecutive sample points with straight lines, you create a piecewise-linear approximation of your function. The area under these line segments is easy to calculate - it's just a sum of trapezoid areas!\n",
    "\n",
    "The integral we seek to approximate is:\n",
    "\n",
    "$$I(a, b) = \\int_a^b f(x)\\,dx$$\n",
    "\n",
    "### Deriving the Formula\n",
    "\n",
    "The area of a single trapezoid with base width $h$ and heights given by function values at two consecutive points is:\n",
    "\n",
    "$$A_k = \\frac{1}{2} h \\left[ f(a + (k - 1)h) + f(a + kh) \\right]$$\n",
    "\n",
    "Summing over all $N$ trapezoids from $x = a$ to $x = b$, we obtain:\n",
    "\n",
    "$$I(a, b) \\approx \\frac{1}{2} h \\sum_{k=1}^N \\left[ f(a + (k - 1)h) + f(a + kh) \\right]$$\n",
    "\n",
    "Rearranging the summation to avoid double-counting interior points:\n",
    "\n",
    "$$I(a, b) \\approx h \\left[ \\frac{1}{2} f(a) + \\frac{1}{2} f(b) + \\sum_{k=1}^{N-1} f(a + kh) \\right]$$\n",
    "\n",
    "This formulation highlights an important computational advantage:  \n",
    "- Interior points $f(a+kh)$ for $k=1,2,...,N-1$ are counted once with full weight\n",
    "- Endpoint values $f(a)$ and $f(b)$ are weighted by $\\frac{1}{2}$ to avoid double-counting\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import integrate as intg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a test function\n",
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "# Integration limits\n",
    "a, b = 0, np.pi\n",
    "N = 3  # Number of intervals\n",
    "\n",
    "# Compute the integral using trapezoid rule\n",
    "trap_result = intg.trapezoidrule(f, a, b, N)\n",
    "\n",
    "# Exact integral value for comparison\n",
    "exact_value = 2.0\n",
    "\n",
    "# Print numerical results\n",
    "print(f\"Exact integral of sin(x) from 0 to π: {exact_value}\")\n",
    "print(f\"Trapezoid Rule (N={N}): {trap_result:.6f}\")\n",
    "print(f\"Absolute error: {abs(trap_result - exact_value):.6f}\")\n",
    "print(f\"Relative error: {abs(trap_result - exact_value)/exact_value * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "x = np.linspace(a, b, N + 1)  # Sample points\n",
    "fx = np.linspace(a, b, 1000)   # High-resolution for smooth curve\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the actual function\n",
    "plt.plot(fx, f(fx), 'k-', linewidth=2, label='f(x) = sin(x)')\n",
    "\n",
    "# Plot the trapezoid approximation (piecewise linear)\n",
    "plt.plot(x, f(x), 'r-', linewidth=1.5, label='Linear approximation')\n",
    "\n",
    "# Fill the area under trapezoids\n",
    "plt.fill_between(x, f(x), alpha=0.3, color='blue', label=\"Trapezoidal area\")\n",
    "\n",
    "# Show the sample points\n",
    "plt.scatter(x, f(x), color='red', s=50, zorder=5)\n",
    "\n",
    "# Annotate one trapezoid to show the geometry\n",
    "if N >= 4:\n",
    "    mid_idx = N // 2\n",
    "    # Draw vertical lines at edges of one trapezoid\n",
    "    plt.plot([x[mid_idx], x[mid_idx]], [0, f(x[mid_idx])], 'g--', linewidth=1, alpha=0.7)\n",
    "    plt.plot([x[mid_idx+1], x[mid_idx+1]], [0, f(x[mid_idx+1])], 'g--', linewidth=1, alpha=0.7)\n",
    "    # Label the width\n",
    "    plt.annotate('', xy=(x[mid_idx+1], -0.12), xytext=(x[mid_idx], -0.12),\n",
    "                arrowprops=dict(arrowstyle='<->', color='green', lw=1.5))\n",
    "    plt.text((x[mid_idx] + x[mid_idx+1])/2, -0.2, 'h', ha='center', fontsize=12, color='green')\n",
    "\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('f(x)', fontsize=12)\n",
    "plt.title(f'Trapezoid Rule Approximation (N = {N} intervals)', fontsize=14)\n",
    "plt.legend(fontsize=10, loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(-0.3, 1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Error\n",
    "\n",
    "How do we know if our approximation is good enough? We can estimate the error using `trapezoiderr()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_estimate = intg.trapezoiderr(f, a, b, N)\n",
    "print(f\"Estimated error: {error_estimate:.6f}\")\n",
    "print(f\"Actual error: {abs(trap_result - exact_value):.6f}\")\n",
    "print(\"\\nThe error estimate is reasonably close to the actual error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does this work?** The error estimation function computes the integral twice:\n",
    "- Once with N steps\n",
    "- Again with N/2 steps (half as many, so larger step size)\n",
    "\n",
    "The difference between these two results tells us approximately how much error remains in the more refined calculation. We'll discuss this technique in more detail later when we cover error analysis.\n",
    "\n",
    "**Key Observation**: Notice that the trapezoid approximation tends to *underestimate* the integral for sin(x). This happens because straight lines cut corners on the curves. For concave-down functions (curving downward), trapezoids underestimate; for concave-up functions, they *overestimate*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpson's Rule\n",
    "\n",
    "The Trapezoid Rule works by connecting consecutive points with straight lines. But what if the function curves significantly between sample points? The straight lines will cut through the curves, missing area above or below.\n",
    "\n",
    "**Simpson's Rule** improves accuracy by fitting parabolas (quadratic curves) instead of straight lines. Since parabolas can curve, they follow the function's shape much better, especially for smooth functions with curvature.\n",
    "\n",
    "*The trade-off*: Simpson's Rule requires an *even* number of intervals ($N$ must be even) because we fit parabolas through groups of three consecutive points.\n",
    "\n",
    "### Deriving Simpson's Rule\n",
    "\n",
    "To derive Simpson's Rule, we approximate the function using a quadratic polynomial over each pair of intervals. Consider three consecutive points with the middle point at the origin:\n",
    "\n",
    "$$f(x) = Ax^2 + Bx + C$$\n",
    "\n",
    "Given function values at three equally-spaced points $x = -h, 0, h$, we can express them in terms of the polynomial coefficients:\n",
    "\n",
    "$$f(-h) = Ah^2 - Bh + C$$\n",
    "$$f(0) = C$$\n",
    "$$f(h) = Ah^2 + Bh + C$$\n",
    "\n",
    "Solving for the coefficients:\n",
    "\n",
    "$$A = \\frac{1}{2h^2} \\left[ f(-h) - 2f(0) + f(h) \\right]$$\n",
    "$$B = \\frac{1}{2h} [f(h) - f(-h)]$$\n",
    "$$C = f(0)$$\n",
    "\n",
    "Now we integrate this quadratic approximation over the interval $[-h, h]$:\n",
    "\n",
    "$$\\int_{-h}^{h} (Ax^2 + Bx + C)\\,dx = \\left[\\frac{Ax^3}{3} + \\frac{Bx^2}{2} + Cx\\right]_{-h}^{h}$$\n",
    "\n",
    "Notice that the $Bx^2$ term vanishes (odd function integrated over symmetric interval):\n",
    "\n",
    "$$= \\frac{2Ah^3}{3} + 2Ch$$\n",
    "\n",
    "Substituting our expressions for $A$ and $C$ and simplifying:\n",
    "\n",
    "$$\\int_{-h}^{h} f(x)\\,dx \\approx \\frac{h}{3} \\left[ f(-h) + 4f(0) + f(h) \\right]$$\n",
    "\n",
    "This is Simpson's Rule for a single parabolic segment.\n",
    "### Generalizing to Multiple Intervals\n",
    "\n",
    "For a general integral $I(a, b) = \\int_a^b f(x)\\,dx$ divided into $N$ intervals (where $N$ must be even), we apply Simpson's formula repeatedly:\n",
    "\n",
    "$$I(a, b) \\approx \\frac{h}{3} \\left[ f(a) + 4f(a + h) + 2f(a + 2h) + 4f(a + 3h) + 2f(a + 4h) + \\cdots + 4f(b-h) + f(b) \\right]$$\n",
    "\n",
    "Notice the pattern of coefficients: **1, 4, 2, 4, 2, 4, ..., 2, 4, 1**\n",
    "\n",
    "We can express this more compactly:\n",
    "\n",
    "$$I(a, b) \\approx \\frac{h}{3} \\left[ f(a) + f(b) + 4 \\sum_{k \\text{ odd}}^{N-1} f(a + kh) + 2 \\sum_{k \\text{ even}}^{N-2} f(a + kh) \\right]$$\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Simpson's Rule uses weighted coefficients**: 4 for odd-indexed points, 2 for even-indexed interior points, 1 for endpoints\n",
    "- **Requires even N**: We need pairs of intervals to fit parabolas through groups of three points\n",
    "- **Higher accuracy than Trapezoid Rule**: For the same step size, Simpson's Rule is significantly more accurate because parabolas capture curvature\n",
    "\n",
    "Let's see Simpson's Rule in action and compare it to the Trapezoid Rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import integrate as intg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the function\n",
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "# Integration limits\n",
    "a, b = 0, np.pi\n",
    "N = 8  # Must be even for Simpson's rule\n",
    "\n",
    "# Compute integrals using both methods\n",
    "trap_result = intg.trapezoidrule(f, a, b, N)\n",
    "simp_result = intg.simpsonrule(f, a, b, N)\n",
    "exact_value = 2.0\n",
    "\n",
    "# Print comparison\n",
    "print(f\"Exact integral: {exact_value}\")\n",
    "print(f\"\\nTrapezoid Rule (N={N}): {trap_result:.10f}\")\n",
    "print(f\"  Error: {abs(trap_result - exact_value):.2e}\")\n",
    "print(f\"\\nSimpson's Rule (N={N}): {simp_result:.10f}\")\n",
    "print(f\"  Error: {abs(simp_result - exact_value):.2e}\")\n",
    "print(f\"\\nSimpson's Rule is {abs(trap_result - exact_value)/abs(simp_result - exact_value):.1f}x more accurate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate x values for visualization\n",
    "x = np.linspace(a, b, N + 1)\n",
    "fx = np.linspace(a, b, 1000)  # High-resolution for smooth curve\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left plot: Trapezoid Rule\n",
    "ax1.plot(fx, f(fx), 'k-', linewidth=2, label='f(x) = sin(x)')\n",
    "ax1.plot(x, f(x), 'r-', linewidth=1.5, label='Linear segments')\n",
    "ax1.fill_between(x, f(x), alpha=0.3, color='red')\n",
    "ax1.scatter(x, f(x), color='red', s=50, zorder=5)\n",
    "ax1.set_xlabel('x', fontsize=12)\n",
    "ax1.set_ylabel('f(x)', fontsize=12)\n",
    "ax1.set_title(f'Trapezoid Rule (N={N})', fontsize=13)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(-0.1, 1.2)\n",
    "\n",
    "# Right plot: Simpson's Rule with parabolic segments\n",
    "ax2.plot(fx, f(fx), 'k-', linewidth=2, label='f(x) = sin(x)')\n",
    "\n",
    "# Draw parabolic segments\n",
    "for i in range(0, N, 2):\n",
    "    x_sample = x[i:i+3]  # Three points for each parabola\n",
    "    y_sample = f(x_sample)\n",
    "    \n",
    "    # Fit a quadratic polynomial\n",
    "    coeffs = np.polyfit(x_sample, y_sample, 2)\n",
    "    \n",
    "    # Generate smooth curve for this parabolic segment\n",
    "    x_curve = np.linspace(x_sample[0], x_sample[-1], 50)\n",
    "    y_curve = np.polyval(coeffs, x_curve)\n",
    "    \n",
    "    # Plot the parabolic segment\n",
    "    ax2.plot(x_curve, y_curve, 'b-', linewidth=1.5)\n",
    "    ax2.fill_between(x_curve, y_curve, alpha=0.3, color='blue')\n",
    "\n",
    "# Scatter plot sample points\n",
    "ax2.scatter(x, f(x), color='blue', s=50, zorder=5, label='Sample points')\n",
    "\n",
    "ax2.set_xlabel('x', fontsize=12)\n",
    "ax2.set_ylabel('f(x)', fontsize=12)\n",
    "ax2.set_title(f\"Simpson's Rule (N={N})\", fontsize=13)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(-0.1, 1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you notice?**\n",
    "\n",
    "Look at how the parabolic segments (blue curves on the right) hug the actual function much more closely than the straight line segments (red, on the left). This is why Simpson's Rule achieves better accuracy with the same number of sample points.\n",
    "\n",
    "The parabolas capture the curvature of sin(x), while straight lines cut through the curves and miss area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate errors for both methods\n",
    "trap_error = intg.trapezoiderr(f, a, b, N)\n",
    "simp_error = intg.simpsonerr(f, a, b, N)\n",
    "\n",
    "print(\"Error Estimates:\")\n",
    "print(f\"Trapezoid Rule: {trap_error:.2e}\")\n",
    "print(f\"Simpson's Rule:  {simp_error:.2e}\")\n",
    "print(f\"\\nSimpson's error estimate is {trap_error/simp_error:.1f}x smaller.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Simpson's Rule\n",
    "\n",
    "**Use Simpson's Rule when:**\n",
    "- You have a smooth function with curvature\n",
    "- You need higher accuracy without dramatically increasing the number of points\n",
    "- Your function can be evaluated at any point (not just pre-existing data)\n",
    "- You can ensure N is even\n",
    "\n",
    "**Use Trapezoid Rule when:**\n",
    "- You have pre-existing data points at irregular intervals\n",
    "- The function is nearly linear over each interval\n",
    "- Simplicity is more important than maximum accuracy\n",
    "- N doesn't need to be even"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Error in Numerical Integration\n",
    "\n",
    "When using numerical integration, we need to understand two competing sources of error:\n",
    "\n",
    "1. **Approximation Error**: The inherent error from approximating a smooth curve with a finite number of geometric shapes\n",
    "2. **Roundoff Error**: Error due to finite precision in computer arithmetic (typically around $10^{-16}$ for standard floating-point numbers)\n",
    "\n",
    "### Good News: Integration Smooths Errors!\n",
    "\n",
    "Unlike numerical differentiation (which amplifies noise), integration tends to **average out** or **smooth** errors. This makes numerical integration:\n",
    "- More stable than differentiation\n",
    "- Less sensitive to noise in data\n",
    "- Generally more accurate with fewer points\n",
    "\n",
    "Think about it physically: when you add up many small contributions (integration), random errors tend to cancel out. When you compute differences (differentiation), errors can compound.\n",
    "\n",
    "### Approximation Errors\n",
    "\n",
    "The Approximation error depends on which method you use and how many steps you take:\n",
    "\n",
    "**Trapezoid Rule**: \n",
    "$$\\epsilon_{trap} \\propto h^2$$\n",
    "\n",
    "This means the Trapezoid Rule is a **second-order method** (accurate to $O(h)$). If you halve the step size $h$, the error decreases by approximately a factor of 4.\n",
    "\n",
    "**Simpson's Rule**: \n",
    "$$\\epsilon_{simp} \\propto h^4$$\n",
    "\n",
    "Simpson's Rule is a **fourth-order method** (accurate to $O(h^3)$). If you halve the step size $h$, the error decreases by approximately a factor of 16!\n",
    "\n",
    "This is why Simpson's Rule is so much more accurate than the Trapezoid Rule for the same number of points.\n",
    "\n",
    "### A Practical Way to Estimate Error\n",
    "\n",
    "In practice, we usually don't know the exact answer (that's why we're integrating numerically). So how do we estimate our error?\n",
    "\n",
    "**The Key Idea**: Compute the integral twice with different step sizes, then use the difference to estimate the error.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "1. Compute the integral with $N$ steps → get result $I_1$\n",
    "2. Compute the integral with $2N$ steps (half the step size) → get result $I_2$\n",
    "3. Use the difference to estimate the error in $I_2$\n",
    "\n",
    "Since we know how error scales with step size:\n",
    "- **For Trapezoid Rule**: The error in $I_2$ is approximately $\\epsilon_2 \\approx \\frac{1}{3}(I_2 - I_1)$\n",
    "- **For Simpson's Rule**: The error in $I_2$ is approximately $\\epsilon_2 \\approx \\frac{1}{15}(I_2 - I_1)$\n",
    "\n",
    "**Why these factors?** When we halve the step size:\n",
    "- Trapezoid error decreases by factor of 4, so: $\\epsilon_1 = 4\\epsilon_2$\n",
    "- From $I_1 + \\epsilon_1 = I_2 + \\epsilon_2$, we get: $I_1 + 4\\epsilon_2 = I_2 + \\epsilon_2$\n",
    "- Solving: $\\epsilon_2 = \\frac{1}{3}(I_2 - I_1)$\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import integrate as intg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define our test function\n",
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "a, b = 0, np.pi\n",
    "exact_value = 2.0\n",
    "\n",
    "# Test with increasing numbers of steps\n",
    "N_values = [4, 8, 16, 32, 64, 128]\n",
    "trap_errors = []\n",
    "simp_errors = []\n",
    "trap_estimates = []\n",
    "simp_estimates = []\n",
    "\n",
    "print(\"N      Trapezoid Error    Estimated    Simpson Error      Estimated\")\n",
    "print(\"-\" * 72)\n",
    "\n",
    "for N in N_values:\n",
    "    # Compute integrals\n",
    "    trap_result = intg.trapezoidrule(f, a, b, N)\n",
    "    simp_result = intg.simpsonrule(f, a, b, N)\n",
    "    \n",
    "    # Actual errors\n",
    "    trap_err = abs(trap_result - exact_value)\n",
    "    simp_err = abs(simp_result - exact_value)\n",
    "    \n",
    "    # Estimated errors\n",
    "    trap_est = intg.trapezoiderr(f, a, b, N)\n",
    "    simp_est = intg.simpsonerr(f, a, b, N)\n",
    "    \n",
    "    trap_errors.append(trap_err)\n",
    "    simp_errors.append(simp_err)\n",
    "    trap_estimates.append(trap_est)\n",
    "    simp_estimates.append(simp_est)\n",
    "    \n",
    "    print(f\"{N:3d}    {trap_err:.6e}    {trap_est:.6e}    {simp_err:.6e}      {simp_est:.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a 3-panel visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Panel 1: Error Convergence Comparison\n",
    "axes[0].loglog(N_values, trap_errors, 'ro-', linewidth=2.5, markersize=9, \n",
    "              label='Trapezoid Rule', alpha=0.8)\n",
    "axes[0].loglog(N_values, simp_errors, 'bs-', linewidth=2.5, markersize=9, \n",
    "              label=\"Simpson's Rule\", alpha=0.8)\n",
    "\n",
    "# Add reference lines (theoretical slopes)\n",
    "N_ref = np.array(N_values)\n",
    "axes[0].loglog(N_ref, 0.5 * (N_ref[0]/N_ref)**2, 'r--', \n",
    "              alpha=0.4, linewidth=2, label='Slope = -2')\n",
    "axes[0].loglog(N_ref, 0.002 * (N_ref[0]/N_ref)**4, 'b--', \n",
    "              alpha=0.4, linewidth=2, label='Slope = -4')\n",
    "\n",
    "axes[0].set_xlabel('Number of intervals (N)', fontsize=11)\n",
    "axes[0].set_ylabel('Absolute Error', fontsize=11)\n",
    "axes[0].set_title('Error Convergence', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3, which='both')\n",
    "\n",
    "# Panel 2: Trapezoid - Estimated vs Actual\n",
    "axes[1].loglog(N_values, trap_errors, 'ro-', linewidth=2.5, markersize=9, \n",
    "              label='Actual Error', alpha=0.8)\n",
    "axes[1].loglog(N_values, trap_estimates, 'r^--', linewidth=2, markersize=7, \n",
    "              alpha=0.6, label='Estimated Error')\n",
    "\n",
    "axes[1].set_xlabel('Number of intervals (N)', fontsize=11)\n",
    "axes[1].set_ylabel('Absolute Error', fontsize=11)\n",
    "axes[1].set_title('Trapezoid Rule:\\nError Estimation', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3, which='both')\n",
    "\n",
    "# Panel 3: Simpson - Estimated vs Actual\n",
    "axes[2].loglog(N_values, simp_errors, 'bs-', linewidth=2.5, markersize=9, \n",
    "              label='Actual Error', alpha=0.8)\n",
    "axes[2].loglog(N_values, simp_estimates, 'b^--', linewidth=2, markersize=7, \n",
    "              alpha=0.6, label='Estimated Error')\n",
    "\n",
    "axes[2].set_xlabel('Number of intervals (N)', fontsize=11)\n",
    "axes[2].set_ylabel('Absolute Error', fontsize=11)\n",
    "axes[2].set_title(\"Simpson's Rule:\\nError Estimation\", fontsize=12, fontweight='bold')\n",
    "axes[2].legend(fontsize=9)\n",
    "axes[2].grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do these plots show?**\n",
    "\n",
    "**Left plot (Error Convergence):**\n",
    "- Both methods improve as N increases (errors go down on this log-log plot)\n",
    "- **Trapezoid Rule** (red) has slope ≈ -2, meaning error ∝ 1/N² (or ∝ h²)\n",
    "- **Simpson's Rule** (blue) has slope ≈ -4, meaning error ∝ 1/N⁴ (or ∝ h⁴)\n",
    "- The dashed reference lines show the theoretical convergence rates\n",
    "- Simpson's Rule is dramatically more accurate for the same N!\n",
    "\n",
    "**Middle plot (Trapezoid Error Estimation):**\n",
    "- Circles show the **actual error** (compared to exact answer)\n",
    "- Triangles show our **estimated error** (from comparing N vs N/2 calculations)\n",
    "- The estimate tracks the actual error quite well!\n",
    "- This means we can trust our error estimates even when we don't know the exact answer\n",
    "\n",
    "**Right plot (Simpson Error Estimation):**\n",
    "- Same idea for Simpson's Rule\n",
    "- Again, estimated errors (triangles) match actual errors (circles) closely\n",
    "- The estimates are reliable for both methods\n",
    "\n",
    "**Why do the estimated and actual errors line up so well?** Because our error estimation technique (computing at two resolutions) correctly captures how the error scales with step size. This validates our approach!\n",
    "\n",
    "### Key Takeaway\n",
    "\n",
    "The error estimation technique works. This means:\n",
    "1. We can estimate how accurate our result is without knowing the exact answer\n",
    "2. We can decide if we need more points to reach our desired accuracy\n",
    "3. We can adaptively refine calculations until we meet our error tolerance\n",
    "\n",
    "This foundation makes Romberg Integration possible - it relies on this same principle of comparing calculations at different resolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Romberg Integration \n",
    "\n",
    "Romberg Integration is a clever technique that takes the simple Trapezoid Rule and systematically refines it to achieve extraordinary accuracy. The key idea: instead of just computing the integral once, we compute it **multiple times** with different step sizes, then *combine the results* to cancel out errors.\n",
    "\n",
    "### The Big Idea\n",
    "\n",
    "Remember from our error analysis that when we computed the integral with N steps and then with 2N steps, we could estimate the error. Romberg Integration takes this further:\n",
    "\n",
    "**What if we don't just estimate the error – what if we use that error estimate to actually *correct* our answer?**\n",
    "\n",
    "This is called **Richardson extrapolation**, and it's simple:\n",
    "\n",
    "1. Compute integral with N steps → get result $R_{1,1}$ (has error ∝ h²)\n",
    "2. Compute with 2N steps → get result $R_{2,1}$ (has error ∝ (h/2)² = h²/4)\n",
    "3. Since we know *how* the error depends on h, we can **extrapolate** to what the answer would be with h = 0!\n",
    "4. This gives us $R_{2,2}$ which is much more accurate (error now ∝ h⁴!)\n",
    "5. Repeat the process: compute with 4N steps, extrapolate again...\n",
    "\n",
    "**The Result**: Each extrapolation step eliminates the leading error term, roughly doubling the number of accurate digits.\n",
    "\n",
    "### The Romberg Process – Step by Step\n",
    "\n",
    "Let's denote $R_{i,1}$ as the Trapezoid Rule result with $N_i = 2^{i-1} \\times N_0$ steps.\n",
    "\n",
    "**First level** - Just trapezoid results:\n",
    "- $R_{1,1}$ = Trapezoid with $N_0$ steps\n",
    "- $R_{2,1}$ = Trapezoid with $2N_0$ steps  \n",
    "- $R_{3,1}$ = Trapezoid with $4N_0$ steps\n",
    "- And so on...\n",
    "\n",
    "**Second level** - Combine pairs to eliminate h² error:\n",
    "\n",
    "$$R_{i,2} = R_{i,1} + \\frac{1}{3}(R_{i,1} - R_{i-1,1})$$\n",
    "\n",
    "This eliminates the h² error term! Now $R_{i,2}$ has error ∝ h⁴ (same as Simpson's Rule).\n",
    "\n",
    "**Third level** - Combine pairs to eliminate h⁴ error:\n",
    "\n",
    "$$R_{i,3} = R_{i,2} + \\frac{1}{15}(R_{i,2} - R_{i-1,2})$$\n",
    "\n",
    "Now error is goes as $h^6$\n",
    "\n",
    "**General formula** - Keep going:\n",
    "\n",
    "$$R_{i,m+1} = R_{i,m} + \\frac{1}{4^m - 1}(R_{i,m} - R_{i-1,m})$$\n",
    "\n",
    "With error estimate:\n",
    "\n",
    "$$\\epsilon_m = \\frac{1}{4^m - 1}(R_{i,m} - R_{i-1,m})$$\n",
    "\n",
    "### Romberg Tableau\n",
    "\n",
    "The Romberg process creates a triangular table of increasingly accurate estimates:\n",
    "```\n",
    "R₁,₁\n",
    "R₂,₁  →  R₂,₂\n",
    "R₃,₁  →  R₃,₂  →  R₃,₃\n",
    "R₄,₁  →  R₄,₂  →  R₄,₃  →  R₄,₄\n",
    "```\n",
    "\n",
    "- Move **down** the first column: Double the number of trapezoids\n",
    "- Move **right** along rows: Apply Richardson extrapolation to eliminate error terms\n",
    "- Each element in the table is more accurate than the one above it\n",
    "- The diagonal elements $R_{i,i}$ are the most accurate estimates\n",
    "\n",
    "**We stop** when $|\\epsilon_m|$ is smaller than our desired tolerance!\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import integrate as intg\n",
    "import numpy as np\n",
    "\n",
    "# Define our test function\n",
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "a, b = 0, np.pi\n",
    "exact_value = 2.0\n",
    "\n",
    "# Set initial N and accuracy target\n",
    "N_initial = 4\n",
    "accuracy = 1e-10\n",
    "\n",
    "print(f\"Computing integral of sin(x) from 0 to π\")\n",
    "print(f\"Exact value: {exact_value}\")\n",
    "print(f\"Target accuracy: {accuracy:.2e}\")\n",
    "print(f\"Starting with N = {N_initial} intervals\\n\")\n",
    "\n",
    "# Compute using Romberg integration\n",
    "romberg_result = intg.rombergrule(f, a, b, N_initial, accuracy=accuracy)\n",
    "\n",
    "print(f\"\\nRomberg result: {romberg_result:.15f}\")\n",
    "print(f\"Exact value:    {exact_value:.15f}\")\n",
    "print(f\"Final error:    {abs(romberg_result - exact_value):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's manually build the Romberg tableau to see the process\n",
    "from numpy import zeros\n",
    "\n",
    "def romberg_tableau(f, a, b, N_start=4, max_iterations=6):\n",
    "    \"\"\"\n",
    "    Build and display the Romberg tableau\n",
    "    \"\"\"\n",
    "    R = zeros([max_iterations, max_iterations])\n",
    "    \n",
    "    # First column: Trapezoid rule with increasing refinement\n",
    "    N = N_start\n",
    "    for i in range(max_iterations):\n",
    "        R[i, 0] = intg.trapezoidrule(f, a, b, N)\n",
    "        N = 2 * N\n",
    "    \n",
    "    # Fill in the rest using Richardson extrapolation\n",
    "    for m in range(1, max_iterations):\n",
    "        for i in range(m, max_iterations):\n",
    "            R[i, m] = R[i, m-1] + (R[i, m-1] - R[i-1, m-1]) / (4**m - 1)\n",
    "    \n",
    "    return R\n",
    "\n",
    "# Build the tableau\n",
    "R = romberg_tableau(f, a, b, N_start=4, max_iterations=6)\n",
    "\n",
    "# Display the tableau\n",
    "print(\"Romberg Tableau:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Row':<5} {'N':<7} {'R[i,1]':<17} {'R[i,2]':<17} {'R[i,3]':<17} {'R[i,4]':<17}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "N = 4\n",
    "for i in range(6):\n",
    "    row_str = f\"{i+1:<5} {N:<7}\"\n",
    "    for m in range(min(i+1, 4)):\n",
    "        error = abs(R[i, m] - exact_value)\n",
    "        row_str += f\" {R[i,m]:.10f} \"\n",
    "        if m < min(i, 3):\n",
    "            row_str += \" \"\n",
    "    print(row_str)\n",
    "    N *= 2\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nExact value: {exact_value:.15f}\")\n",
    "print(f\"\\nNotice how:\")\n",
    "print(f\"  - Each row is more accurate than the previous row\")\n",
    "print(f\"  - Each column is more accurate than the previous column\")\n",
    "print(f\"  - The diagonal elements R[i,i] are the most accurate!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For a fair comparison, we need to control what Romberg is actually doing\n",
    "# Let's compute errors at fixed N values for both methods\n",
    "\n",
    "N_values = [4, 8, 16, 32, 64, 128, 256]\n",
    "trap_errors = []\n",
    "simp_errors = []\n",
    "romberg_errors = []\n",
    "\n",
    "print(f\"{'N':<8} {'Trapezoid Error':<20} {'Simpson Error':<20} {'Romberg Error':<20}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for N in N_values:\n",
    "    # Trapezoid error\n",
    "    trap_result = intg.trapezoidrule(f, a, b, N)\n",
    "    trap_err = abs(trap_result - exact_value)\n",
    "    trap_errors.append(trap_err)\n",
    "    \n",
    "    # Simpson error (if N is even)\n",
    "    if N % 2 == 0:\n",
    "        simp_result = intg.simpsonrule(f, a, b, N)\n",
    "        simp_err = abs(simp_result - exact_value)\n",
    "        simp_errors.append(simp_err)\n",
    "    else:\n",
    "        simp_errors.append(np.nan)\n",
    "    \n",
    "    # Romberg with this starting N (but let it iterate to high accuracy)\n",
    "    romberg_result = intg.rombergrule(f, a, b, N, accuracy=1e-15)\n",
    "    romberg_err = abs(romberg_result - exact_value)\n",
    "    romberg_errors.append(romberg_err)\n",
    "    \n",
    "    print(f\"{N:<8} {trap_err:<20.2e} {simp_err:<20.2e} {romberg_err:<20.2e}\")\n",
    "\n",
    "# Plot convergence\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(N_values, trap_errors, 'ro-', \n",
    "            linewidth=2, markersize=8, label='Trapezoid Rule', alpha=0.7)\n",
    "plt.semilogy([n for n in N_values if n%2==0], [e for n,e in zip(N_values, simp_errors) if n%2==0], \n",
    "            'gs-', linewidth=2, markersize=8, label=\"Simpson's Rule\", alpha=0.7)\n",
    "plt.semilogy(N_values, romberg_errors, 'b^-', \n",
    "            linewidth=2, markersize=8, label='Romberg Integration', alpha=0.7)\n",
    "\n",
    "# Add a horizontal line at machine epsilon\n",
    "machine_eps = np.finfo(float).eps\n",
    "plt.axhline(y=machine_eps, color='gray', linestyle='--', linewidth=1.5, \n",
    "           alpha=0.7, label=f'Machine precision (~{machine_eps:.0e})')\n",
    "\n",
    "plt.xlabel('Number of initial intervals (N)', fontsize=12)\n",
    "plt.ylabel('Absolute Error (log scale)', fontsize=12)\n",
    "plt.title('Convergence Comparison: Trapezoid vs Simpson vs Romberg', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "plt.ylim(1e-17, 1e0)\n",
    "\n",
    "# Add annotation\n",
    "plt.text(100, 1e-11, 'Romberg reaches\\nmachine precision\\nfirst!', \n",
    "        fontsize=10, ha='center', \n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Find where each method reaches a certain accuracy threshold\n",
    "threshold = 1e-10\n",
    "print(f\"\\nTo reach accuracy of {threshold:.0e}:\")\n",
    "for i, N in enumerate(N_values):\n",
    "    if trap_errors[i] < threshold:\n",
    "        print(f\"  Trapezoid Rule: N = {N} (error = {trap_errors[i]:.2e})\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"  Trapezoid Rule: Needs N > {N_values[-1]}\")\n",
    "\n",
    "for i, N in enumerate(N_values):\n",
    "    if N % 2 == 0 and simp_errors[i] < threshold:\n",
    "        print(f\"  Simpson's Rule:  N = {N} (error = {simp_errors[i]:.2e})\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"  Simpson's Rule: Needs N > {N_values[-1]}\")\n",
    "    \n",
    "for i, N in enumerate(N_values):\n",
    "    if romberg_errors[i] < threshold:\n",
    "        print(f\"  Romberg:        N = {N} (error = {romberg_errors[i]:.2e})\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"  Romberg: Needs N > {N_values[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "Look at the Romberg tableau carefully:\n",
    "\n",
    "1. **First column** ($R_{i,1}$): These are just Trapezoid Rule results with increasing N\n",
    "   - Still has significant error\n",
    "   - Improves slowly as we double N\n",
    "\n",
    "2. **Second column** ($R_{i,2}$): First extrapolation\n",
    "   - Eliminates the h² error term\n",
    "   - Accuracy jumps dramatically!\n",
    "   - Roughly equivalent to Simpson's Rule\n",
    "\n",
    "3. **Third column and beyond**: Further extrapolations\n",
    "   - Each step eliminates the next error term\n",
    "   - Accuracy improves exponentially\n",
    "   - Quickly approaches machine precision (~10⁻¹⁶)\n",
    "\n",
    "4. **The diagonal** ($R_{i,i}$): Best estimates\n",
    "   - These are the most refined values at each level\n",
    "   - Each one uses information from all previous calculations\n",
    "\n",
    "### The Power of Romberg Integration\n",
    "\n",
    "**Why is this so effective?**\n",
    "\n",
    "- **Reuses computations**: Each trapezoid calculation reuses function evaluations from the previous level\n",
    "- **Systematic error elimination**: Each extrapolation removes the dominant error term\n",
    "- **Exponential convergence**: Error decreases exponentially, not just polynomially\n",
    "- **Adaptive**: Automatically refines until target accuracy is reached\n",
    "\n",
    "**Practical advantages:**\n",
    "- Can achieve 10⁻¹⁰ accuracy with relatively few function evaluations\n",
    "- Much more efficient than simply using tiny step sizes\n",
    "- Built-in error estimation tells you when to stop\n",
    "\n",
    "### When to Use Romberg Integration\n",
    "\n",
    "**Use Romberg when:**\n",
    "- You need high accuracy (many significant figures)\n",
    "- You can evaluate the function at any point (not limited to fixed data)\n",
    "- The function is smooth (no sharp corners or discontinuities)\n",
    "- You want automatic adaptive refinement\n",
    "\n",
    "**Don't use Romberg when:**\n",
    "- You have pre-existing data at fixed points (can't choose new sample points)\n",
    "- The function has discontinuities or sharp features\n",
    "- Simple accuracy is sufficient (Trapezoid or Simpson is easier)\n",
    "- Function evaluations are extremely expensive (Romberg needs many evaluations)\n",
    "\n",
    "**The bottom line**: Romberg Integration is one of the most powerful techniques for smooth, well-behaved functions where high accuracy is needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Using Python's Built-in Integration Tools\n",
    "\n",
    "Python has powerful integration tools in the `scipy.integrate` module. These are production-quality implementations that you should use in real research and applications. Let's see how they compare to our custom functions.\n",
    "\n",
    "### Why use scipy.integrate?\n",
    "\n",
    "- **Highly optimized**: Written in C/Fortran for speed\n",
    "- **Well-tested**: Used by scientists worldwide\n",
    "- **Adaptive**: Automatically adjusts step sizes for optimal accuracy\n",
    "- **Feature-rich**: Handles special cases (infinite limits, singularities, etc.)\n",
    "\n",
    "Let's compare our custom functions with scipy's implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as sci\n",
    "sci?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second line will list how the contents and summary of the functions within the module *scipy.integrate*. Also note that I have included my own integration algorithms (**user beware**) in `integrate.py`.\n",
    "\n",
    "\n",
    "For these examples, we'll switch it up and evaluate an integral that has great importance in statistical mechanics,\n",
    "$$ \\int_a^b \\frac{x^3}{e^{x}-1} dx $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as sci\n",
    "import integrate as intg\n",
    "import numpy as np\n",
    "\n",
    "# Define a test function - important in statistical mechanics!\n",
    "# This integral appears in calculating blackbody radiation\n",
    "def f(x):\n",
    "    return x**3 / (np.exp(x) - 1)\n",
    "\n",
    "a, b = 1, 8\n",
    "N = 100\n",
    "\n",
    "print(\"Comparing custom functions with scipy.integrate\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Integrating x³/(e^x - 1) from {a} to {b}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Trapezoid Rule\n",
    "custom_trap = intg.trapezoidrule(f, a, b, N)\n",
    "x_array = np.linspace(a, b, N+1)\n",
    "y_array = f(x_array)\n",
    "scipy_trap = sci.trapezoid(y_array, x_array)\n",
    "\n",
    "print(f\"\\nTrapezoid Rule (N={N}):\")\n",
    "print(f\"  Custom function:  {custom_trap:.10f}\")\n",
    "print(f\"  scipy.trapezoid: {scipy_trap:.10f}\")\n",
    "print(f\"  Difference:       {abs(custom_trap - scipy_trap):.2e}\")\n",
    "\n",
    "# Simpson's Rule\n",
    "custom_simp = intg.simpsonrule(f, a, b, N)\n",
    "scipy_simp = sci.simpson(y_array, x=x_array)\n",
    "\n",
    "print(f\"\\nSimpson's Rule (N={N}):\")\n",
    "print(f\"  Custom function: {custom_simp:.10f}\")\n",
    "print(f\"  scipy.simpson:   {scipy_simp:.10f}\")\n",
    "print(f\"  Difference:      {abs(custom_simp - scipy_simp):.2e}\")\n",
    "\n",
    "# Romberg Integration\n",
    "custom_romb = intg.rombergrule(f, a, b, max_iters=8, accuracy=1e-10)\n",
    "scipy_romb = sci.romberg(f, a, b)\n",
    "\n",
    "print(f\"\\nRomberg Integration:\")\n",
    "print(f\"  Custom function: {custom_romb:.10f}\")\n",
    "print(f\"  scipy.romberg:   {scipy_romb:.10f}\")\n",
    "print(f\"  Difference:      {abs(custom_romb - scipy_romb):.2e}\")\n",
    "\n",
    "# The most general scipy function: quad (adaptive quadrature)\n",
    "result, error = sci.quad(f, a, b)\n",
    "\n",
    "print(f\"\\nscipy.quad (adaptive, high-accuracy):\")\n",
    "print(f\"  Result:          {result:.10f}\")\n",
    "print(f\"  Error estimate:  {error:.2e}\")\n",
    "print(f\"\\nNote: scipy.quad is the 'gold standard' - use this in real applications!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Integration Function Should You Use?\n",
    "\n",
    "**For learning and understanding algorithms:**\n",
    "- Use your custom `integrate.py` functions\n",
    "- They show you exactly what's happening under the hood\n",
    "\n",
    "**For real research and applications:**\n",
    "- **`scipy.integrate.quad()`** - Your default choice for 1D integration\n",
    "  - Adaptive: automatically finds the right step size\n",
    "  - Handles difficult integrals (oscillatory, peaked, etc.)\n",
    "  - Returns both result and error estimate\n",
    "  \n",
    "- **`scipy.integrate.trapezoid()` or `scipy.integrate.simpson()`** - When you have pre-existing data points\n",
    "  - Can't choose new sample locations\n",
    "  - Fast for regularly-spaced data\n",
    "  \n",
    "- **`scipy.integrate.romberg()`** - Probably never since this function is deprecated and slated for removal.\n",
    "\n",
    "**The bottom line**: For homework and learning, use your custom functions. For research, use `scipy.quad()` unless you have a specific reason not to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Multiple Integrals (Advanced)\n",
    "\n",
    "So far we've integrated functions of one variable: $\\int_a^b f(x)\\,dx$. In physics and engineering, we often need to integrate over 2D or 3D regions:\n",
    "\n",
    "- **Surface integrals**: Electric flux through a surface\n",
    "- **Volume integrals**: Total mass or charge in a region  \n",
    "- **Probability**: Normalizing multi-variable distributions\n",
    "\n",
    "Python's `scipy.integrate` handles this with `dblquad()` (double integrals) and `tplquad()` (triple integrals).\n",
    "\n",
    "**Important**: The order of limits in Python is *reversed* from standard mathematical notation!\n",
    "\n",
    "### Double Integral Example\n",
    "\n",
    "Compute: $$\\int_{0}^{3}\\int_{0}^{1-2x} x^2 y\\,dy\\,dx$$\n",
    "\n",
    "Notice the inner integral has limits that depend on x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the integrand\n",
    "def integrand(y, x):  # Note: arguments are in reverse order!\n",
    "    return x**2 * y\n",
    "\n",
    "# Define the limits\n",
    "# Inner integral: y from 0 to (1-2x)\n",
    "# Outer integral: x from 0 to 3\n",
    "result, error = sci.dblquad(integrand, \n",
    "                            0, 3,              # x limits (outer)\n",
    "                            lambda x: 0,        # y lower limit (inner)\n",
    "                            lambda x: 1 - 2*x)  # y upper limit (inner)\n",
    "\n",
    "print(f\"Double integral result: {result:.6f}\")\n",
    "print(f\"Error estimate: {error:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key points about double integrals in Python:**\n",
    "1. Function arguments are reversed: `def f(y, x)` not `def f(x, y)`\n",
    "2. Limits are specified outer-to-inner: x limits first, then y limits\n",
    "3. Variable limits use lambda functions: `lambda x: 1-2*x`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The triple integral below is $$\\int_{0}^{2}\\int_{0}^{3-x}\\int_{1}^{4-x-y}x^2y+3z$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triple integral example\n",
    "# ∫∫∫ (x²y + 3z) dz dy dx\n",
    "# where: x from 0 to 2, y from 0 to (3-x), z from 1 to (4-x-y)\n",
    "\n",
    "def integrand_3d(z, y, x):  # Reversed order!\n",
    "    return x**2 * y + 3 * z\n",
    "\n",
    "result, error = sci.tplquad(integrand_3d,\n",
    "                            0, 2,                    # x limits (outermost)\n",
    "                            lambda x: 0,             # y lower\n",
    "                            lambda x: 3 - x,         # y upper\n",
    "                            lambda x, y: 1,          # z lower\n",
    "                            lambda x, y: 4 - x - y)  # z upper\n",
    "\n",
    "print(f\"Triple integral result: {result:.6f}\")\n",
    "print(f\"Error estimate: {error:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise: The Anharmonic Oscillator\n",
    "\n",
    "### Background\n",
    "\n",
    "In introductory physics, you studied the *simple harmonic oscillator* - a mass on a spring with potential energy $V(x) = \\frac{1}{2}kx^2$. This oscillator has a special property: its period $T$ doesn't depend on the amplitude $A$. Whether you pull the mass back 1 cm or 10 cm, it takes the same time to complete one oscillation.\n",
    "\n",
    "But real oscillators aren't *perfectly* harmonic. A pendulum with large swings, a vibrating molecule, or a spring stretched beyond its linear range all have more complicated potentials. These **anharmonic oscillators** have periods that depend on amplitude, and we can't write down a simple formula for $T(A)$.\n",
    "\n",
    "However, we *can* compute $T(A)$ numerically using integration!\n",
    "\n",
    "### The Physics\n",
    "\n",
    "For any oscillator with potential $V(x)$, conservation of energy gives:\n",
    "\n",
    "$$E = \\frac{1}{2}m\\left(\\frac{dx}{dt}\\right)^2 + V(x)$$\n",
    "\n",
    "If the oscillator starts at maximum displacement $x = a$ (the amplitude) with zero velocity, then $E = V(a)$.\n",
    "\n",
    "At any other position, the velocity is:\n",
    "\n",
    "$$\\frac{dx}{dt} = \\sqrt{\\frac{2}{m}[V(a) - V(x)]}$$\n",
    "\n",
    "The period is four times the time to go from $x=0$ to $x=a$:\n",
    "\n",
    "$$T = 4\\int_{0}^{a} \\frac{dx}{\\sqrt{\\frac{2}{m}[V(a) - V(x)]}}$$\n",
    "\n",
    "For simplicity, let's set $m = 1$.\n",
    "\n",
    "### Your Tasks\n",
    "\n",
    "**1. Harmonic Oscillator** (Warm-up)\n",
    "\n",
    "For the harmonic potential $V(x) = x^2$, write a function that computes the period $T$ as a function of amplitude $a$ using numerical integration.\n",
    "\n",
    "- Use `scipy.integrate.quad()` for the integration\n",
    "- Test with amplitudes $a = 0.5, 1, 2, 4$\n",
    "- **Verify** that the period is constant (doesn't depend on $a$) as expected\n",
    "- Compare to the theoretical value: $T = 2\\pi\\sqrt{m/k} = 2\\pi$ (since we set $k=1, m=1$)\n",
    "\n",
    "**Hint**: The integrand has a singularity at $x=a$ (division by zero). To avoid this, integrate from 0 to $a - \\epsilon$ where $\\epsilon$ is a small number like 0.001.\n",
    "\n",
    "**2. Anharmonic Oscillator**\n",
    "\n",
    "Now consider the anharmonic potential $V(x) = x^4$. This represents a \"stiff\" spring that gets harder to stretch as you pull it further.\n",
    "\n",
    "- Compute $T(a)$ for amplitudes $a = 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0$\n",
    "- Create a plot of $T$ vs $a$\n",
    "- Does the period increase or decrease with amplitude?\n",
    "- **Physical interpretation**: Why does this make sense?\n",
    "\n",
    "**3. Comparison**\n",
    "\n",
    "Create a single plot comparing the period vs amplitude for both the harmonic ($V = x^2$) and anharmonic ($V = x^4$) oscillators.\n",
    "\n",
    "- Use different colors/markers for each\n",
    "- Add labels and a legend\n",
    "- What's the qualitative difference between the two curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate as sci\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def period(V, a, m=1, ep = 0.001):\n",
    "    \"\"\"\n",
    "    Compute the period of an oscillator with potential V(x) and amplitude a\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
